import os
import requests
from supabase import create_client
from typing import Optional, Dict, Any, List
from dotenv import load_dotenv
from datetime import datetime, timedelta
import random
import google.generativeai as genai
import time
import logging
import db

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()


SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY_ANON = os.getenv("SUPABASE_KEY_ANON")

supabase_anon = None
supabase_service = None

try:
    supabase_anon = create_client(SUPABASE_URL, SUPABASE_KEY_ANON)
    logger.info("‚úÖ Supabase cliente AN√ìNIMO inicializado correctamente")
except Exception as e:
    logger.error(f"‚ùå Error inicializando Supabase an√≥nimo: {e}")

try:
    SUPABASE_SERVICE_KEY = os.getenv("SUPABASE_KEY")
    if SUPABASE_SERVICE_KEY:
        supabase_service = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)
        logger.info("‚úÖ Supabase cliente SERVICE ROLE inicializado correctamente")
except Exception as e:
    logger.warning(f"‚ö†Ô∏è No se pudo inicializar Supabase Service Role: {e}")


supabase = supabase_service if supabase_service else supabase_anon

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_01")
GEMINI_MODEL = "gemini-2.5-flash"
MAX_REQUESTS_PER_DAY = 25


CATEGORIAS_NOTICIAS = {
    "Negocios": ["negocio", "negocios", "finanza", "finanzas", "econom√≠a", "economia", "empresa", "mercado", "inversi√≥n", "inversion", "burs√°til", "bursatil"],
    "Entretenimiento": ["entretenimiento", "cine", "pel√≠cula", "pelicula", "m√∫sica", "musica", "show", "celebridad", "famoso", "espect√°culo", "espectaculo"],
    "Salud": ["salud", "medicina", "m√©dico", "medico", "hospital", "enfermedad", "tratamiento", "bienestar"],
    "Ciencia": ["ciencia", "cient√≠fico", "cientifico", "investigaci√≥n", "investigacion", "descubrimiento", "estudio", "tecnolog√≠a", "tecnologia", "innovaci√≥n", "innovacion"],
    "Deportes": ["deporte", "deportes", "f√∫tbol", "futbol", "partido", "jugador", "equipo", "competici√≥n", "competicion", "liga"],
    "Tecnolog√≠a": ["tecnolog√≠a", "tecnologia", "tech", "digital", "software", "hardware", "aplicaci√≥n", "aplicacion", "app", "internet"],
    "General": ["general", "noticia", "actualidad", "√∫ltima", "ultima", "reciente"]
}


SECCIONES_ESPECIALES = {
    "clima_actual": {
        "nombre": "Clima Actual",
        "descripcion": "Muestra el clima en tu ciudad actual y en otras ciudades importantes del mundo. Datos meteorol√≥gicos en tiempo real.",
        "palabras_clave": ["clima", "tiempo", "meteorol√≥gico", "meteorologico", "temperatura", "lluvia", "soleado", "pron√≥stico", "pronostico"]
    },
    "mundo_futbol": {
        "nombre": "Mundo F√∫tbol", 
        "descripcion": "Resultados recientes, pr√≥ximos partidos, calendarios de Premier League, Liga Espa√±ola, Champions League y Serie A.",
        "palabras_clave": ["f√∫tbol", "futbol", "partido", "resultado", "liga", "premier", "champions", "calendario", "equipo"]
    },
    "mundo_inversion": {
        "nombre": "Mundo Inversi√≥n",
        "descripcion": "Cotizaciones de divisas, acciones, √≠ndices burs√°tiles y criptomonedas en tiempo real.",
        "palabras_clave": ["inversi√≥n", "inversion", "divisa", "acci√≥n", "accion", "bolsa", "criptomoneda", "bitcoin", "d√≥lar", "dolar", "euro", "mercado"]
    },
    "ventana_del_universo": {
        "nombre": "Ventana del Universo",
        "descripcion": "Astronomy Picture of the Day (APOD) de la NASA - Im√°genes astron√≥micas diarias con explicaciones.",
        "palabras_clave": ["universo", "nasa", "astronom√≠a", "astronomia", "espacio", "planeta", "estrella", "galaxia", "cosmos"]
    },
    "frase_del_dia": {
        "nombre": "Frase del D√≠a",
        "descripcion": "Frase inspiradora o reflexiva que cambia diariamente para motivar a los usuarios.",
        "palabras_clave": ["frase", "inspiradora", "motivaci√≥n", "motivacion", "reflexi√≥n", "reflexion", "sabidur√≠a", "sabiduria", "pensamiento"]
    }
}

print("üîß DIAGN√ìSTICO GEMINI:")
print(f"‚úÖ GEMINI_API_KEY_01 existe: {bool(GEMINI_API_KEY)}")

gemini_model = None
try:
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)
        gemini_model = genai.GenerativeModel("gemini-2.5-flash")
        
        print("üîÑ Probando conexi√≥n con Gemini 2.5 Flash...")
        test_response = gemini_model.generate_content("Responde solo 'CONECTADO'")
        if test_response and test_response.text:
            print(f"‚úÖ Gemini 2.5 Flash configurado correctamente - Test: {test_response.text.strip()}")
        else:
            print("‚ùå Gemini respondi√≥ pero sin texto")
            gemini_model = None
    else:
        print("‚ùå ERROR CR√çTICO: GEMINI_API_KEY_01 no encontrada en variables de entorno")
        gemini_model = None
except Exception as e:
    print(f"‚ùå Error configurando Gemini 2.5 Flash: {e}")
    gemini_model = None


CONTEXTO_BASE_WEB = """
Eres AntiBot, el asistente inteligente de AntiHumo News. Tu prop√≥sito es ayudar a los usuarios con informaci√≥n veraz sobre noticias y contenido del sitio.

INFORMACI√ìN CR√çTICA SOBRE EL SITIO:

1. CATEGOR√çAS DE NOTICIAS (contenido noticioso real):
   ‚Ä¢ Negocios - Noticias financieras, econ√≥micas, empresariales
   ‚Ä¢ Entretenimiento - Cine, m√∫sica, espect√°culos, celebridades
   ‚Ä¢ Salud - Medicina, bienestar, tratamientos, investigaciones m√©dicas
   ‚Ä¢ Ciencia - Descubrimientos, investigaciones cient√≠ficas, avances
   ‚Ä¢ Deportes - F√∫tbol, competiciones, partidos, resultados
   ‚Ä¢ Tecnolog√≠a - Innovaciones tech, software, hardware, digital
   ‚Ä¢ General - Noticias variadas y de actualidad

2. SECCIONES ESPECIALES DEL HOME (NO son noticias tradicionales):
   ‚Ä¢ Clima Actual - Datos meteorol√≥gicos en tiempo real
   ‚Ä¢ Mundo F√∫tbol - Resultados, calendarios de ligas internacionales
   ‚Ä¢ Mundo Inversi√≥n - Cotizaciones de divisas, acciones, criptomonedas
   ‚Ä¢ Ventana del Universo - Im√°genes astron√≥micas diarias de la NASA (APOD)
   ‚Ä¢ Frase del D√≠a - Frase inspiradora diaria

REGLAS ESTRICTAS DE COMPORTAMIENTO:
- SOLO saludas en el PRIMER mensaje de la conversaci√≥n
- Respuestas directas, √∫tiles y espec√≠ficas
- NO repetir informaci√≥n innecesariamente
- Reconocer cuando no se tiene informaci√≥n espec√≠fica
- Para recomendaciones: usar √öLTIMA noticia disponible de la categor√≠a
- Para secciones especiales: explicar QU√â son y QU√â muestran

PALABRAS CLAVE PARA DETECCI√ìN:
‚Ä¢ "recomienda", "sugiere", "qu√© noticia" ‚Üí RECOMENDACI√ìN
‚Ä¢ "clima", "tiempo" ‚Üí SECCI√ìN CLIMA
‚Ä¢ "f√∫tbol", "partido", "liga" ‚Üí SECCI√ìN MUNDO F√öTBOL
‚Ä¢ "inversi√≥n", "divisa", "bolsa" ‚Üí SECCI√ìN MUNDO INVERSI√ìN
‚Ä¢ "universo", "nasa", "espacio" ‚Üí SECCI√ìN VENTANA UNIVERSO
‚Ä¢ "frase", "inspiraci√≥n" ‚Üí SECCI√ìN FRASE DEL D√çA
"""

class ChatBotService:
    def __init__(self):
        self.contexto_base = CONTEXTO_BASE_WEB
        self.modelo_actual = GEMINI_MODEL
        self.rate_limit_cache = {}
        self.conversaciones_activas = {} 
        logger.info("ü§ñ ChatBotService inicializado - Versi√≥n Mejorada 1000%")
   
    def verificar_rate_limit(self, user_ip: str) -> Dict[str, Any]:
        """Verifica y actualiza el rate limit por IP"""
        ahora = datetime.now()
        fecha_actual = ahora.date()
        
        if user_ip in self.rate_limit_cache:
            cache_data = self.rate_limit_cache[user_ip]
            
            if cache_data['fecha'] == fecha_actual:
                if cache_data['contador'] >= MAX_REQUESTS_PER_DAY:
                    manana = ahora + timedelta(days=1)
                    manana_medianoche = manana.replace(hour=0, minute=0, second=0, microsecond=0)
                    segundos_restantes = (manana_medianoche - ahora).seconds
                    horas_restantes = segundos_restantes // 3600
                    minutos_restantes = (segundos_restantes % 3600) // 60
                    
                    return {
                        "permitido": False,
                        "mensaje": f"‚è∞ L√≠mite diario alcanzado ({MAX_REQUESTS_PER_DAY} preguntas). Nuevas preguntas en {horas_restantes}h {minutos_restantes}m.",
                        "contador_actual": cache_data['contador'],
                        "limite": MAX_REQUESTS_PER_DAY,
                        "reset_time": manana_medianoche.isoformat()
                    }
                else:
                    cache_data['contador'] += 1
                    preguntas_restantes = MAX_REQUESTS_PER_DAY - cache_data['contador']
                    return {
                        "permitido": True,
                        "mensaje": f"üìä Preguntas: {cache_data['contador']}/{MAX_REQUESTS_PER_DAY}",
                        "contador_actual": cache_data['contador'],
                        "limite": MAX_REQUESTS_PER_DAY,
                        "preguntas_restantes": preguntas_restantes
                    }
            else:
                self.rate_limit_cache[user_ip] = {
                    'fecha': fecha_actual,
                    'contador': 1
                }
                return {
                    "permitido": True,
                    "mensaje": f"üìä Preguntas: 1/{MAX_REQUESTS_PER_DAY}",
                    "contador_actual": 1,
                    "limite": MAX_REQUESTS_PER_DAY,
                    "preguntas_restantes": MAX_REQUESTS_PER_DAY - 1
                }
        else:
            self.rate_limit_cache[user_ip] = {
                'fecha': fecha_actual,
                'contador': 1
            }
            return {
                "permitido": True,
                "mensaje": f"üìä Preguntas: 1/{MAX_REQUESTS_PER_DAY}",
                "contador_actual": 1,
                "limite": MAX_REQUESTS_PER_DAY,
                "preguntas_restantes": MAX_REQUESTS_PER_DAY - 1
            }
   
    def limpiar_cache_antiguo(self):
        """Limpia caches antiguos para evitar memory leaks"""
        fecha_actual = datetime.now().date()
        

        ips_a_eliminar = []
        for ip, data in self.rate_limit_cache.items():
            if (fecha_actual - data['fecha']).days > 2:
                ips_a_eliminar.append(ip)
        for ip in ips_a_eliminar:
            del self.rate_limit_cache[ip]
        

        conversaciones_a_eliminar = []
        ahora = datetime.now()
        for ip, data in self.conversaciones_activas.items():
            if (ahora - data['ultima_interaccion']).seconds > 3600: 
                conversaciones_a_eliminar.append(ip)
        for ip in conversaciones_a_eliminar:
            del self.conversaciones_activas[ip]
        
        if ips_a_eliminar or conversaciones_a_eliminar:
            logger.info(f"üßπ Limpiadas {len(ips_a_eliminar)} IPs y {len(conversaciones_a_eliminar)} conversaciones antiguas")
   
    def obtener_contexto_noticia(self, noticia_id: int) -> Optional[Dict[str, Any]]:
        """Obtiene una noticia espec√≠fica por ID"""
        try:
            if not supabase:
                logger.error("‚ùå Supabase no est√° inicializado")
                return None
            
            response = supabase.table("noticias").select("*").eq("id", noticia_id).execute()
            if not response.data:
                logger.warning(f"‚ùå Noticia {noticia_id} no encontrada en Supabase")
                return None
            
            noticia = response.data[0]
            logger.info(f"‚úÖ Noticia {noticia_id} encontrada: {noticia['titulo'][:50]}...")
            return noticia
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo noticia {noticia_id}: {e}")
            return None
   
    def construir_contexto_noticia(self, noticia: Dict[str, Any]) -> str:
        """Construye el contexto espec√≠fico para una noticia"""
        contexto = f"""
üì∞ CONTEXTO DE NOTICIA PARA AN√ÅLISIS:

TITULAR: {noticia['titulo']}

RESUMEN COMPLETO:
{noticia['resumen']}

INFORMACI√ìN ADICIONAL:
‚Ä¢ Categor√≠a: {noticia.get('categoria', 'No especificada')}
‚Ä¢ Fuente: {noticia.get('fuente', 'No especificada')}
‚Ä¢ Fecha: {noticia.get('fecha', 'No especificada')}

INSTRUCCIONES PARA TI:
Eres un analista de noticias. El usuario te har√° preguntas SOBRE ESTA NOTICIA ESPEC√çFICA.
‚Ä¢ Responde basado √öNICAMENTE en la informaci√≥n proporcionada arriba
‚Ä¢ Si algo no est√° claro en la noticia, recon√≥celo amablemente
‚Ä¢ S√© objetivo y enf√≥cate en los hechos presentados
"""
        return contexto
    
    def inicializar_chat_gemini(self, user_ip: str, contexto_sistema: str):
        """Inicializa o reinicia un chat de Gemini para un usuario"""
        try:
            if not gemini_model:
                return None
            

            chat_session = gemini_model.start_chat(history=[])
            
            chat_session.send_message(f"""
{contexto_sistema}

INSTRUCCI√ìN INICIAL: 
Eres AntiBot de AntiHumo News. Mant√©n conversaciones naturales y √∫tiles. 
SOLO saluda en el primer mensaje de cada sesi√≥n.
Responde de forma directa y enfocada en ayudar.
""")
            
            self.conversaciones_activas[user_ip] = {
                'chat': chat_session,
                'ultima_interaccion': datetime.now(),
                'primer_mensaje': True,
                'contexto_actual': None  
            }
            
            logger.info(f"‚úÖ Chat Gemini inicializado para IP: {user_ip}")
            return chat_session
            
        except Exception as e:
            logger.error(f"‚ùå Error inicializando chat Gemini: {e}")
            return None
    
    def obtener_chat_gemini(self, user_ip: str, contexto_sistema: str) -> Any:
        """Obtiene el chat activo de Gemini o crea uno nuevo"""
        ahora = datetime.now()
        
        if user_ip in self.conversaciones_activas:
            datos_chat = self.conversaciones_activas[user_ip]
            

            if (ahora - datos_chat['ultima_interaccion']).seconds > 1800:
                logger.info(f"üîÑ Reiniciando chat por inactividad para IP: {user_ip}")
                return self.inicializar_chat_gemini(user_ip, contexto_sistema)
            
            datos_chat['ultima_interaccion'] = ahora
            datos_chat['primer_mensaje'] = False
            return datos_chat['chat']
        else:

            return self.inicializar_chat_gemini(user_ip, contexto_sistema)
    
    def es_primer_mensaje(self, user_ip: str) -> bool:
        """Determina si es el primer mensaje del usuario en esta sesi√≥n"""
        if user_ip not in self.conversaciones_activas:
            return True
        
        es_primer = self.conversaciones_activas[user_ip]['primer_mensaje']
        self.conversaciones_activas[user_ip]['primer_mensaje'] = False
        return es_primer
    
    def construir_prompt_inteligente(self, pregunta: str, contexto: str, es_primer_mensaje: bool, 
                                   tipo_contexto: str, noticia_data: Optional[Dict] = None) -> str:
        """Construye un prompt inteligente basado en el contexto y tipo de consulta"""
        
        saludo = "¬°Hola! Soy AntiBot de AntiHumo News. " if es_primer_mensaje else ""
        
        if tipo_contexto == "recomendacion":
            if noticia_data:
                prompt_especifico = f"""
{saludo}El usuario est√° pidiendo una recomendaci√≥n de noticia. 

NOTICIA RECOMENDADA DISPONIBLE:
‚Ä¢ T√≠tulo: {noticia_data['titulo']}
‚Ä¢ Resumen: {noticia_data['resumen']}
‚Ä¢ Categor√≠a: {noticia_data.get('categoria', 'General')}

RESPONDE:
- Recomienda esta noticia espec√≠fica mencionando el titular
- Explica brevemente por qu√© es relevante
- Usa un tono natural y √∫til
- NO digas "te recomiendo esta noticia" de forma gen√©rica
- Integra la recomendaci√≥n en tu respuesta naturalmente
"""
            else:
                prompt_especifico = f"""
{saludo}El usuario quiere una recomendaci√≥n pero no hay noticias recientes en esa categor√≠a.

RESPONDE:
- Informa amablemente que no hay noticias recientes en esa categor√≠a
- Sugiere explorar otras categor√≠as como General o Deportes
- Mant√©n un tono √∫til y proactivo
"""
        
        elif tipo_contexto == "seccion_especial":
            seccion_info = noticia_data
            prompt_especifico = f"""
{saludo}El usuario est√° preguntando sobre la secci√≥n: {seccion_info['nombre']}

INFORMACI√ìN DE LA SECCI√ìN:
‚Ä¢ Descripci√≥n: {seccion_info['descripcion']}

RESPONDE:
- Explica claramente qu√© es esta secci√≥n y qu√© muestra
- Enfatiza que NO es una noticia tradicional
- Describe el tipo de contenido que el usuario encontrar√° all√≠
- Usa un tono informativo y √∫til
"""
        
        elif tipo_contexto == "noticia_especifica":
            prompt_especifico = f"""
{saludo}El usuario est√° preguntando sobre una noticia espec√≠fica.

CONTEXTO DE LA NOTICIA:
‚Ä¢ T√≠tulo: {noticia_data['titulo']}
‚Ä¢ Resumen: {noticia_data['resumen']}

RESPONDE:
- Basa tu respuesta √öNICAMENTE en la informaci√≥n de esta noticia
- S√© preciso y objetivo con los hechos presentados
- Si la pregunta no puede responderse con la informaci√≥n disponible, recon√≥celo amablemente
"""
        
        else:  
            prompt_especifico = f"""
{saludo}El usuario est√° haciendo una pregunta general.

RESPONDE:
- De forma directa y √∫til
- Enf√≥cate en ayudar con informaci√≥n real del sitio
- Si no tienes informaci√≥n espec√≠fica, sugiere explorar las categor√≠as
- Mant√©n un tono profesional pero amigable
"""

        return f"""{prompt_especifico}

PREGUNTA DEL USUARIO: {pregunta}

RESPONDE de forma natural y directa:"""
    
    def clasificar_intencion(self, pregunta: str) -> Dict[str, Any]:
        """Clasificaci√≥n MUCHO m√°s precisa de la intenci√≥n del usuario"""
        pregunta_lower = pregunta.lower().strip()
        

        palabras_recomendacion = ["recomienda", "sugiere", "qu√© noticia", "noticia de", "√∫ltima noticia", "noticia nueva", "recomiendas"]
        if any(palabra in pregunta_lower for palabra in palabras_recomendacion):
            for categoria, palabras_clave in CATEGORIAS_NOTICIAS.items():
                if any(clave in pregunta_lower for clave in palabras_clave):
                    return {"tipo": "recomendacion_categoria", "categoria": categoria}
        

        for seccion_id, seccion_info in SECCIONES_ESPECIALES.items():
            if any(clave in pregunta_lower for clave in seccion_info["palabras_clave"]):
                return {"tipo": "seccion_especial", "seccion": seccion_id, "info": seccion_info}
        

        if "noticia" in pregunta_lower and any(word in pregunta_lower for word in ["qu√©", "c√≥mo", "cu√°ndo", "d√≥nde", "por qu√©"]):
            return {"tipo": "consulta_especifica", "categoria": None}
        
        return {"tipo": "general", "categoria": None}
    
    def llamar_gemini_con_chat(self, prompt: str, user_ip: str, contexto_sistema: str) -> str:
        """Llama a Gemini usando chat con historial"""
        try:
            if not gemini_model:
                logger.error("‚ùå Gemini no est√° configurado correctamente")
                return self.get_fallback_response("")
            

            chat_session = self.obtener_chat_gemini(user_ip, contexto_sistema)
            if not chat_session:
                return self.get_fallback_response(prompt)
            
            logger.info("üîÑ Enviando mensaje a Gemini Chat API...")
            

            response = chat_session.send_message(prompt)
            
            if response and response.text:
                respuesta = response.text.strip()
                logger.info("‚úÖ Respuesta recibida de Gemini Chat")
                

                if "noticia" in prompt.lower() or "recomienda" in prompt.lower():
                    self.conversaciones_activas[user_ip]['contexto_actual'] = "discutiendo_noticia"
                
                return respuesta
            else:
                logger.warning("‚ùå Gemini no devolvi√≥ texto en la respuesta")
                return self.get_fallback_response(prompt)
               
        except Exception as e:
            logger.error(f"‚ùå Error llamando a Gemini Chat: {e}")
            return self.get_fallback_response(prompt)
    
    def get_fallback_response(self, prompt: str) -> str:
        """Respuestas de fallback mejoradas"""
        prompt_lower = prompt.lower()
        

        if any(palabra in prompt_lower for palabra in ["recomienda", "sugiere", "noticia de"]):
            return "üì∞ Actualmente no tengo noticias recientes en esa categor√≠a espec√≠fica. Te sugiero explorar las secciones de 'General' o 'Deportes' donde suele haber contenido actualizado."
        
        if any(palabra in prompt_lower for palabra in ["clima", "tiempo"]):
            return "üå§Ô∏è En la secci√≥n 'Clima Actual' puedes ver el tiempo en tu ciudad y otras ciudades del mundo. Son datos meteorol√≥gicos en tiempo real, no noticias tradicionales."
        
        if any(palabra in prompt_lower for palabra in ["f√∫tbol", "futbol", "partido", "liga"]):
            return "‚öΩ La secci√≥n 'Mundo F√∫tbol' muestra resultados recientes, pr√≥ximos partidos y calendarios de ligas como Premier League, Champions League y m√°s."
        
        if any(palabra in prompt_lower for palabra in ["inversi√≥n", "inversion", "bolsa", "divisa"]):
            return "üìà En 'Mundo Inversi√≥n' encontrar√°s cotizaciones de divisas, acciones y criptomonedas en tiempo real. Es informaci√≥n financiera actualizada."
        
        if any(palabra in prompt_lower for palabra in ["universo", "nasa", "espacio"]):
            return "ü™ê La 'Ventana del Universo' muestra la Astronomy Picture of the Day de la NASA - im√°genes astron√≥micas espectaculares con explicaciones."
        
        return "ü§ñ Puedo ayudarte a encontrar noticias por categor√≠a o explicarte las secciones especiales del sitio. ¬øQu√© te interesa explorar?"
    
    def generar_respuesta(self, pregunta: str, noticia_id: Optional[int] = None, user_ip: str = "desconocida") -> Dict[str, Any]:
        try:

            rate_limit_check = self.verificar_rate_limit(user_ip)
            
            if not rate_limit_check["permitido"]:
                return {
                    "respuesta": rate_limit_check["mensaje"],
                    "tipo_contexto": "rate_limit",
                    "noticia_id": noticia_id,
                    "noticia_info": "limite_excedido",
                    "titulo_noticia": None,
                    "exito": False,
                    "modelo": "rate_limit",
                    "rate_limit_info": rate_limit_check
                }


            es_primer_mensaje = self.es_primer_mensaje(user_ip)
            

            intencion = self.clasificar_intencion(pregunta)
            
            contexto = self.contexto_base
            tipo_contexto = intencion["tipo"]
            noticia_info = "sin_noticia"
            titulo_noticia = None
            noticia_data = None
            

            if noticia_id:
                noticia_data = self.obtener_contexto_noticia(noticia_id)
                if noticia_data:
                    contexto = self.construir_contexto_noticia(noticia_data)
                    tipo_contexto = "noticia_especifica"
                    noticia_info = "noticia_encontrada"
                    titulo_noticia = noticia_data['titulo']
                else:
                    noticia_info = "noticia_no_encontrada"
            
            elif intencion["tipo"] == "recomendacion_categoria":
                categoria = intencion["categoria"]
                

                noticia_data = db.get_latest_noticia_by_category(categoria)
                
                if noticia_data:
                    titulo_noticia = noticia_data['titulo']
                    noticia_info = "recomendacion_encontrada"
                    tipo_contexto = "recomendacion"
                else:
                    noticia_info = "recomendacion_no_encontrada"
                    tipo_contexto = "recomendacion"
                    noticia_data = {"categoria": categoria}
            
            elif intencion["tipo"] == "seccion_especial":
                seccion_info = intencion["info"]
                noticia_data = seccion_info
                noticia_info = "seccion_especial"
                tipo_contexto = "seccion_especial"
                titulo_noticia = seccion_info["nombre"]
            

            prompt_final = self.construir_prompt_inteligente(
                pregunta, contexto, es_primer_mensaje, tipo_contexto, noticia_data
            )
            

            respuesta = self.llamar_gemini_con_chat(prompt_final, user_ip, contexto)
            
            logger.info(f"‚úÖ Respuesta generada - Tipo: {tipo_contexto}, Longitud: {len(respuesta)}")
            
            return {
                "respuesta": respuesta,
                "tipo_contexto": tipo_contexto,
                "noticia_id": noticia_id,
                "noticia_info": noticia_info,
                "titulo_noticia": titulo_noticia,
                "exito": True,
                "modelo": self.modelo_actual,
                "rate_limit_info": rate_limit_check
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error generando respuesta: {e}")
            return {
                "respuesta": "‚ö†Ô∏è Ocurri√≥ un error inesperado. Por favor, intenta nuevamente.",
                "tipo_contexto": "error",
                "noticia_id": noticia_id,
                "noticia_info": "error",
                "titulo_noticia": None,
                "exito": False,
                "modelo": "error",
                "rate_limit_info": None
            }


chatbot_service = ChatBotService()

try:
    test_result = chatbot_service.generar_respuesta("test de conexi√≥n", None, "test_init")
    if test_result["exito"]:
        print(f"‚úÖ Test inicial exitoso: {test_result['respuesta'][:80]}...")
    else:
        print(f"‚ö†Ô∏è Test inicial con problemas: {test_result['respuesta']}")
except Exception as e:
    print(f"‚ùå Error en test inicial: {e}")