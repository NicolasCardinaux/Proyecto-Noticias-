import os
import requests
from supabase import create_client
from typing import Optional, Dict, Any
from dotenv import load_dotenv
from datetime import datetime, timedelta
import random
import google.generativeai as genai
import time
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

try:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    logger.info("‚úÖ Supabase cliente inicializado correctamente")
except Exception as e:
    logger.error(f"‚ùå Error inicializando Supabase: {e}")
    supabase = None

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_01")
GEMINI_MODEL = "gemini-2.5-flash"
MAX_REQUESTS_PER_DAY = 30

print("üîß DIAGN√ìSTICO GEMINI:")
print(f"‚úÖ GEMINI_API_KEY_01 existe: {bool(GEMINI_API_KEY)}")
print(f"‚úÖ Longitud API Key: {len(GEMINI_API_KEY or '')}")
if GEMINI_API_KEY:
    print(f"‚úÖ Primeros 10 chars: {GEMINI_API_KEY[:10]}...")

print(f"üîß Inicializando ChatBot Service con Gemini 2.5 Flash...")
print(f"‚úÖ L√≠mite: {MAX_REQUESTS_PER_DAY} preguntas por d√≠a por IP")
print(f"‚úÖ Supabase configurado: {bool(SUPABASE_URL)}")

gemini_model = None
try:
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)
        gemini_model = genai.GenerativeModel("gemini-2.5-flash")
        
        print("üîÑ Probando conexi√≥n con Gemini 2.5 Flash...")
        test_response = gemini_model.generate_content("Responde solo 'CONECTADO'")
        if test_response and test_response.text:
            print(f"‚úÖ Gemini 2.5 Flash configurado correctamente - Test: {test_response.text}")
        else:
            print("‚ùå Gemini respondi√≥ pero sin texto")
            gemini_model = None
    else:
        print("‚ùå ERROR CR√çTICO: GEMINI_API_KEY_01 no encontrada en variables de entorno")
        gemini_model = None
except Exception as e:
    print(f"‚ùå Error configurando Gemini 2.5 Flash: {e}")
    gemini_model = None

CONTEXTO_BASE_WEB = """
Eres AntiBot, el asistente inteligente de AntiHumo News. Tu prop√≥sito es ayudar a los usuarios con informaci√≥n sobre noticias y contenido del sitio.

Eres un especialista en noticias que puede:
‚Ä¢ Analizar y explicar noticias ESPEC√çFICAS de AntiHumo News
‚Ä¢ Responder preguntas sobre el contenido de noticias publicadas
‚Ä¢ Ayudar a navegar categor√≠as y funcionalidades del sitio
‚Ä¢ Contextualizar informaci√≥n basada en noticias reales

SOBRE ANTIHUMO NEWS:
‚Ä¢ Agregador de noticias argentinas y globales
‚Ä¢ Res√∫menes con IA que eliminan amarillismo y sesgos
‚Ä¢ Informaci√≥n verificada y sin "humo" informativo
‚Ä¢ Secciones: Noticias, Clima, Deportes, Mercados, NASA, Tecnolog√≠a

C√ìMO RESPONDER:
1. Cuando hay una noticia espec√≠fica: Analiza y responde basado EN EL CONTENIDO de esa noticia
2. Cuando es sobre el sitio: Explica funcionalidades y categor√≠as
3. Cuando es pregunta general sobre noticias: Responde brevemente si est√° relacionado con temas noticiosos actuales
4. Cuando NO puedes responder: Di amablemente tu l√≠mite

L√çMITES CLAROS:
NO PUEDES:
‚Ä¢ Crear noticias ficticias o inventar informaci√≥n
‚Ä¢ Dar consejos m√©dicos, legales o financieros
‚Ä¢ Hacer predicciones futuras no basadas en hechos
‚Ä¢ Responder sobre temas completamente ajenos a noticias

Responde de forma √∫til, veraz y siempre basado en hechos reales cuando haya noticias de referencia.
"""

class ChatBotService:
    def __init__(self):
        self.contexto_base = CONTEXTO_BASE_WEB
        self.modelo_actual = GEMINI_MODEL
        self.rate_limit_cache = {}
        logger.info("ü§ñ ChatBotService inicializado")
    
    def verificar_rate_limit(self, user_ip: str) -> Dict[str, Any]:
        ahora = datetime.now()
        fecha_actual = ahora.date()
        
        if user_ip in self.rate_limit_cache:
            cache_data = self.rate_limit_cache[user_ip]
            
            if cache_data['fecha'] == fecha_actual:
                if cache_data['contador'] >= MAX_REQUESTS_PER_DAY:
                    manana = ahora + timedelta(days=1)
                    manana_medianoche = manana.replace(hour=0, minute=0, second=0, microsecond=0)
                    segundos_restantes = (manana_medianoche - ahora).seconds
                    horas_restantes = segundos_restantes // 3600
                    minutos_restantes = (segundos_restantes % 3600) // 60
                    
                    return {
                        "permitido": False,
                        "mensaje": f"‚è∞ Has alcanzado el l√≠mite de {MAX_REQUESTS_PER_DAY} preguntas por d√≠a. Podr√°s hacer m√°s preguntas en {horas_restantes}h {minutos_restantes}m.",
                        "contador_actual": cache_data['contador'],
                        "limite": MAX_REQUESTS_PER_DAY,
                        "reset_time": manana_medianoche.isoformat()
                    }
                else:
                    cache_data['contador'] += 1
                    preguntas_restantes = MAX_REQUESTS_PER_DAY - cache_data['contador']
                    return {
                        "permitido": True,
                        "mensaje": f"üìä Usadas: {cache_data['contador']}/{MAX_REQUESTS_PER_DAY} | Restantes: {preguntas_restantes}",
                        "contador_actual": cache_data['contador'],
                        "limite": MAX_REQUESTS_PER_DAY,
                        "preguntas_restantes": preguntas_restantes
                    }
            else:
                self.rate_limit_cache[user_ip] = {
                    'fecha': fecha_actual,
                    'contador': 1
                }
                return {
                    "permitido": True,
                    "mensaje": f"üìä Usadas: 1/{MAX_REQUESTS_PER_DAY} | Restantes: {MAX_REQUESTS_PER_DAY - 1}",
                    "contador_actual": 1,
                    "limite": MAX_REQUESTS_PER_DAY,
                    "preguntas_restantes": MAX_REQUESTS_PER_DAY - 1
                }
        else:
            self.rate_limit_cache[user_ip] = {
                'fecha': fecha_actual,
                'contador': 1
            }
            return {
                "permitido": True,
                "mensaje": f"üìä Usadas: 1/{MAX_REQUESTS_PER_DAY} | Restantes: {MAX_REQUESTS_PER_DAY - 1}",
                "contador_actual": 1,
                "limite": MAX_REQUESTS_PER_DAY,
                "preguntas_restantes": MAX_REQUESTS_PER_DAY - 1
            }
    
    def limpiar_cache_antiguo(self):
        fecha_actual = datetime.now().date()
        ips_a_eliminar = []
        
        for ip, data in self.rate_limit_cache.items():
            if (fecha_actual - data['fecha']).days > 2:
                ips_a_eliminar.append(ip)
        
        for ip in ips_a_eliminar:
            del self.rate_limit_cache[ip]
            
        if ips_a_eliminar:
            logger.info(f"üßπ Limpiadas {len(ips_a_eliminar)} IPs antiguas del cache")
    
    def obtener_contexto_noticia(self, noticia_id: int) -> Optional[Dict[str, Any]]:
        try:
            if not supabase:
                logger.error("‚ùå Supabase no est√° inicializado")
                return None
                
            response = supabase.table("noticias").select("*").eq("id", noticia_id).execute()
            
            if not response.data:
                logger.warning(f"‚ùå Noticia {noticia_id} no encontrada en Supabase")
                return None
            
            noticia = response.data[0]
            logger.info(f"‚úÖ Noticia {noticia_id} encontrada: {noticia['titulo'][:50]}...")
            
            return noticia
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo noticia {noticia_id}: {e}")
            return None
    
    def construir_contexto_noticia(self, noticia: Dict[str, Any]) -> str:
        contexto = f"""
üì∞ CONTEXTO DE NOTICIA PARA AN√ÅLISIS:

TITULAR: {noticia['titulo']}

RESUMEN COMPLETO: 
{noticia['resumen']}

INFORMACI√ìN ADICIONAL:
‚Ä¢ Categor√≠a: {noticia.get('categoria', 'No especificada')}
‚Ä¢ Fuente: {noticia.get('fuente', 'No especificada')}
‚Ä¢ Fecha: {noticia.get('fecha', 'No especificada')}

INSTRUCCIONES PARA TI:
Eres un analista de noticias. El usuario te har√° preguntas SOBRE ESTA NOTICIA ESPEC√çFICA.
‚Ä¢ Responde basado √öNICAMENTE en la informaci√≥n proporcionada arriba
‚Ä¢ Si algo no est√° claro en la noticia, recon√≥celo amablemente
‚Ä¢ S√© objetivo y enf√≥cate en los hechos presentados
‚Ä¢ Puedes explicar el contexto y significado de lo que S√ç est√° en la noticia

EJEMPLO:
Si el usuario pregunta "¬øQu√© pas√≥ con [persona]?" ‚Üí Explica lo que la noticia dice sobre esa persona
Si pregunta "¬øCu√°ndo ocurri√≥?" ‚Üí Usa las fechas de la noticia
Si pregunta "¬øPor qu√© es importante?" ‚Üí Analiza el impacto basado en el contenido
"""
        return contexto
    
    def llamar_gemini_api(self, prompt: str) -> str:
        try:
            if not gemini_model:
                logger.error("‚ùå Gemini no est√° configurado correctamente")
                return self.get_fallback_response("")
            
            logger.info("üîÑ Enviando pregunta a Gemini 2.5 Flash API...")
            
            generation_config = {
                "temperature": 0.3,
                "top_p": 0.9,
                "top_k": 40,
                "max_output_tokens": 800,
            }
            
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"}
            ]
            
            response = gemini_model.generate_content(
                prompt,
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            
            if response.text:
                respuesta = response.text.strip()
                logger.info("‚úÖ Respuesta recibida de Gemini 2.5 Flash")
                return respuesta
            else:
                logger.warning("‚ùå Gemini no devolvi√≥ texto en la respuesta")
                return self.get_fallback_response(prompt)
                
        except Exception as e:
            logger.error(f"‚ùå Error llamando a Gemini: {e}")
            return self.get_fallback_response(prompt)
    
    def get_fallback_response(self, prompt: str) -> str:
        if not gemini_model:
            return "ü§ñ Hola! Soy AntiBot de AntiHumo News. Actualmente estoy en modo de respuestas b√°sicas. Puedo ayudarte a navegar el sitio y sus categor√≠as. ¬øEn qu√© necesitas ayuda?"
        
        prompt_lower = prompt.lower()
        
        fallback_responses = {
            "hola": "¬°Hola! ü§ñ Soy AntiBot de AntiHumo News. Puedo ayudarte a entender noticias espec√≠ficas o explicarte sobre nuestro sitio. ¬øEn qu√© necesitas ayuda?",
            "holaa": "¬°Hola! üëã Soy AntiBot. Puedo analizar noticias espec√≠ficas o ayudarte a navegar AntiHumo News. ¬øSobre qu√© noticia quieres hablar?",
            "qu√© puedes hacer": "Puedo: üì∞ Analizar noticias espec√≠ficas publicadas, üîç Explicar categor√≠as del sitio, üìä Ayudarte a navegar AntiHumo News. ¬øSobre qu√© noticia quieres hablar?",
            "noticias": "üì∞ En AntiHumo News encontrar√°s noticias actualizadas de Argentina y el mundo, resumidas con IA para eliminar el amarillismo. ¬°Explora las diferentes categor√≠as!",
            "clima": "üå§Ô∏è En AntiHumo News tenemos una secci√≥n de clima con pron√≥sticos actualizados. Puedes consultarla en nuestro sitio para informaci√≥n meteorol√≥gica.",
            "deportes": "‚öΩ Tenemos una secci√≥n dedicada a deportes con las √∫ltimas noticias. ¬°Navega por la categor√≠a Deportes en AntiHumo News para ver lo √∫ltimo!",
            "tecnolog√≠a": "üíª En nuestra secci√≥n de Tecnolog√≠a encontrar√°s las √∫ltimas novedades en innovaci√≥n. Visita AntiHumo News para ver el contenido actualizado.",
            "ayuda": "ü§ñ Puedo ayudarte a entender noticias espec√≠ficas, explicar categor√≠as del sitio y guiarte en AntiHumo News. ¬øSobre qu√© noticia necesitas informaci√≥n?",
            "nasa": "üöÄ Tenemos contenido de la NASA incluyendo la Astronomy Picture of the Day (APOD). ¬°Es una de nuestras secciones m√°s populares!",
            "mercados": "üìà En AntiHumo News cubrimos noticias de mercados financieros y econ√≥micas. Revisa nuestra secci√≥n de Econom√≠a para estar actualizado.",
            "wall street": "üìä Wall Street se basa en an√°lisis de empresas, tendencias econ√≥micas, datos macroecon√≥micos y expectativas de mercado para hacer sus estimaciones.",
            "econom√≠a": "üíπ En nuestra secci√≥n de Econom√≠a encontrar√°s an√°lisis de mercados, tendencias financieras y noticias econ√≥micas actualizadas."
        }
        
        palabras_fuera_contexto = [
            "calcula", "resuelve", "ecuaci√≥n", "matem√°tica pura", 
            "consejo m√©dico", "consejo legal", "qu√© droga", "ilegal",
            "futuro predicci√≥n", "hor√≥scopo", "magia", "hechizo",
            "f√≥rmula qu√≠mica", "teorema", "√°lgebra", "trigonometr√≠a"
        ]
        
        for palabra in palabras_fuera_contexto:
            if palabra in prompt_lower:
                return "üö´ Lo siento, no puedo ayudarte con ese tipo de consultas. Mi especialidad es noticias y contenido de AntiHumo News."
        
        for keyword, response in fallback_responses.items():
            if keyword in prompt_lower:
                return response
        
        if "wall street" in prompt_lower or "estimaci√≥n" in prompt_lower or "mercado" in prompt_lower:
            return "üìà Wall Street basa sus estimaciones en an√°lisis fundamental de empresas, tendencias macroecon√≥micas, datos hist√≥ricos, proyecciones de crecimiento y condiciones del mercado global."
        
        return "ü§ñ ¬°Hola! Soy AntiBot de AntiHumo News. Puedo ayudarte a entender noticias espec√≠ficas publicadas en nuestro sitio. ¬øTienes alguna noticia en mente sobre la que quieras hablar? Tambi√©n puedo explicarte las categor√≠as y funcionalidades disponibles."
    
    def generar_respuesta(self, pregunta: str, noticia_id: Optional[int] = None, user_ip: str = "desconocida") -> Dict[str, Any]:
        try:
            rate_limit_check = self.verificar_rate_limit(user_ip)
            
            if not rate_limit_check["permitido"]:
                logger.warning(f"üö´ Rate limit excedido para IP: {user_ip}")
                return {
                    "respuesta": rate_limit_check["mensaje"],
                    "tipo_contexto": "rate_limit",
                    "noticia_id": noticia_id,
                    "noticia_info": "limite_excedido",
                    "titulo_noticia": None,
                    "exito": False,
                    "modelo": "rate_limit",
                    "rate_limit_info": rate_limit_check
                }
            
            if random.random() < 0.1:
                self.limpiar_cache_antiguo()
            
            if noticia_id:
                noticia_data = self.obtener_contexto_noticia(noticia_id)
                if noticia_data:
                    contexto = self.construir_contexto_noticia(noticia_data)
                    tipo_contexto = "noticia"
                    noticia_info = "noticia_encontrada"
                    titulo_noticia = noticia_data['titulo']
                else:
                    contexto = self.contexto_base
                    tipo_contexto = "general"
                    noticia_info = "noticia_no_encontrada"
                    titulo_noticia = None
            else:
                contexto = self.contexto_base
                tipo_contexto = "general"
                noticia_info = "sin_noticia"
                titulo_noticia = None
            
            prompt_final = f"""{contexto}

PREGUNTA DEL USUARIO: {pregunta}

RESPONDE AHORA (en espa√±ol, de forma natural y √∫til):"""
            
            respuesta = self.llamar_gemini_api(prompt_final)
            
            logger.info(f"‚úÖ Respuesta generada - Tipo: {tipo_contexto}, Longitud: {len(respuesta)}")
            
            return {
                "respuesta": respuesta,
                "tipo_contexto": tipo_contexto,
                "noticia_id": noticia_id,
                "noticia_info": noticia_info,
                "titulo_noticia": titulo_noticia,
                "exito": True,
                "modelo": self.modelo_actual,
                "rate_limit_info": rate_limit_check
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error generando respuesta: {e}")
            return {
                "respuesta": "‚ùå Lo siento, ocurri√≥ un error inesperado. Por favor, intenta nuevamente. ‚ö†Ô∏è",
                "tipo_contexto": "error",
                "noticia_id": noticia_id,
                "noticia_info": "error",
                "titulo_noticia": None,
                "exito": False,
                "modelo": "error",
                "rate_limit_info": None
            }


chatbot_service = ChatBotService()
print("‚úÖ ChatBot Service con Gemini 2.5 Flash (30 preguntas/d√≠a) inicializado correctamente")

try:
    test_result = chatbot_service.generar_respuesta("Hola, ¬øest√°s funcionando?", None, "test_init")
    if test_result["exito"]:
        print(f"‚úÖ Test inicial exitoso: {test_result['respuesta'][:50]}...")
    else:
        print(f"‚ö†Ô∏è Test inicial con problemas: {test_result['respuesta']}")
        print("üîß El bot est√° en modo fallback. Verifica GEMINI_API_KEY_01 en Render.")
except Exception as e:
    print(f"‚ùå Error en test inicial: {e}")