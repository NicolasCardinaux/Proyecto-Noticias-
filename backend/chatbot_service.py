import os
import requests
from supabase import create_client
from typing import Optional, Dict, Any
from dotenv import load_dotenv
from datetime import datetime, timedelta
import random
import google.generativeai as genai
import time
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

try:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    logger.info("âœ… Supabase cliente inicializado correctamente")
except Exception as e:
    logger.error(f"âŒ Error inicializando Supabase: {e}")
    supabase = None

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_01")
GEMINI_MODEL = "gemini-2.5-flash"
MAX_REQUESTS_PER_DAY = 30

print("ðŸ”§ DIAGNÃ“STICO GEMINI:")
print(f"âœ… GEMINI_API_KEY_01 existe: {bool(GEMINI_API_KEY)}")
print(f"âœ… Longitud API Key: {len(GEMINI_API_KEY or '')}")
if GEMINI_API_KEY:
    print(f"âœ… Primeros 10 chars: {GEMINI_API_KEY[:10]}...")

print(f"ðŸ”§ Inicializando ChatBot Service con Gemini 2.5 Flash...")
print(f"âœ… LÃ­mite: {MAX_REQUESTS_PER_DAY} preguntas por dÃ­a por IP")
print(f"âœ… Supabase configurado: {bool(SUPABASE_URL)}")

gemini_model = None
try:
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)
        gemini_model = genai.GenerativeModel("gemini-2.5-flash")
        
        print("ðŸ”„ Probando conexiÃ³n con Gemini 2.5 Flash...")
        test_response = gemini_model.generate_content("Responde solo 'CONECTADO'")
        if test_response and test_response.text:
            print(f"âœ… Gemini 2.5 Flash configurado correctamente - Test: {test_response.text}")
        else:
            print("âŒ Gemini respondiÃ³ pero sin texto")
            gemini_model = None
    else:
        print("âŒ ERROR CRÃTICO: GEMINI_API_KEY_01 no encontrada en variables de entorno")
        gemini_model = None
except Exception as e:
    print(f"âŒ Error configurando Gemini 2.5 Flash: {e}")
    gemini_model = None

CONTEXTO_BASE_WEB = """
Eres AntiBot, el asistente inteligente de AntiHumo News. Tu propÃ³sito es ayudar a los usuarios con informaciÃ³n sobre noticias y contenido del sitio.

Eres un especialista en noticias que puede:
â€¢ Analizar y explicar noticias ESPECÃFICAS de AntiHumo News
â€¢ Responder preguntas sobre el contenido de noticias publicadas
â€¢ Ayudar a navegar categorÃ­as y funcionalidades del sitio
â€¢ Contextualizar informaciÃ³n basada en noticias reales

SOBRE ANTIHUMO NEWS:
â€¢ Agregador de noticias argentinas y globales
â€¢ ResÃºmenes con IA que eliminan amarillismo y sesgos
â€¢ InformaciÃ³n verificada y sin "humo" informativo
â€¢ Secciones: Noticias, Clima, Deportes, Mercados, NASA, TecnologÃ­a

CÃ“MO RESPONDER:
1. Cuando hay una noticia especÃ­fica: Analiza y responde basado EN EL CONTENIDO de esa noticia
2. Cuando es sobre el sitio: Explica funcionalidades y categorÃ­as
3. Cuando es pregunta general sobre noticias: Responde brevemente si estÃ¡ relacionado con temas noticiosos actuales
4. Cuando NO puedes responder: Di amablemente tu lÃ­mite

LÃMITES CLAROS:
NO PUEDES:
â€¢ Crear noticias ficticias o inventar informaciÃ³n
â€¢ Dar consejos mÃ©dicos, legales o financieros
â€¢ Hacer predicciones futuras no basadas en hechos
â€¢ Responder sobre temas completamente ajenos a noticias

Responde de forma Ãºtil, veraz y siempre basado en hechos reales cuando haya noticias de referencia.
"""

class ChatBotService:
    def __init__(self):
        self.contexto_base = CONTEXTO_BASE_WEB
        self.modelo_actual = GEMINI_MODEL
        self.rate_limit_cache = {}
        logger.info("ðŸ¤– ChatBotService inicializado")
    
    def verificar_rate_limit(self, user_ip: str) -> Dict[str, Any]:
        ahora = datetime.now()
        fecha_actual = ahora.date()
        
        if user_ip in self.rate_limit_cache:
            cache_data = self.rate_limit_cache[user_ip]
            
            if cache_data['fecha'] == fecha_actual:
                if cache_data['contador'] >= MAX_REQUESTS_PER_DAY:
                    manana = ahora + timedelta(days=1)
                    manana_medianoche = manana.replace(hour=0, minute=0, second=0, microsecond=0)
                    segundos_restantes = (manana_medianoche - ahora).seconds
                    horas_restantes = segundos_restantes // 3600
                    minutos_restantes = (segundos_restantes % 3600) // 60
                    
                    return {
                        "permitido": False,
                        "mensaje": f"â° Has alcanzado el lÃ­mite de {MAX_REQUESTS_PER_DAY} preguntas por dÃ­a. PodrÃ¡s hacer mÃ¡s preguntas en {horas_restantes}h {minutos_restantes}m.",
                        "contador_actual": cache_data['contador'],
                        "limite": MAX_REQUESTS_PER_DAY,
                        "reset_time": manana_medianoche.isoformat()
                    }
                else:
                    cache_data['contador'] += 1
                    preguntas_restantes = MAX_REQUESTS_PER_DAY - cache_data['contador']
                    return {
                        "permitido": True,
                        "mensaje": f"ðŸ“Š Usadas: {cache_data['contador']}/{MAX_REQUESTS_PER_DAY} | Restantes: {preguntas_restantes}",
                        "contador_actual": cache_data['contador'],
                        "limite": MAX_REQUESTS_PER_DAY,
                        "preguntas_restantes": preguntas_restantes
                    }
            else:
                self.rate_limit_cache[user_ip] = {
                    'fecha': fecha_actual,
                    'contador': 1
                }
                return {
                    "permitido": True,
                    "mensaje": f"ðŸ“Š Usadas: 1/{MAX_REQUESTS_PER_DAY} | Restantes: {MAX_REQUESTS_PER_DAY - 1}",
                    "contador_actual": 1,
                    "limite": MAX_REQUESTS_PER_DAY,
                    "preguntas_restantes": MAX_REQUESTS_PER_DAY - 1
                }
        else:
            self.rate_limit_cache[user_ip] = {
                'fecha': fecha_actual,
                'contador': 1
            }
            return {
                "permitido": True,
                "mensaje": f"ðŸ“Š Usadas: 1/{MAX_REQUESTS_PER_DAY} | Restantes: {MAX_REQUESTS_PER_DAY - 1}",
                "contador_actual": 1,
                "limite": MAX_REQUESTS_PER_DAY,
                "preguntas_restantes": MAX_REQUESTS_PER_DAY - 1
            }
    
    def limpiar_cache_antiguo(self):
        fecha_actual = datetime.now().date()
        ips_a_eliminar = []
        
        for ip, data in self.rate_limit_cache.items():
            if (fecha_actual - data['fecha']).days > 2:
                ips_a_eliminar.append(ip)
        
        for ip in ips_a_eliminar:
            del self.rate_limit_cache[ip]
            
        if ips_a_eliminar:
            logger.info(f"ðŸ§¹ Limpiadas {len(ips_a_eliminar)} IPs antiguas del cache")
    
    def obtener_contexto_noticia(self, noticia_id: int) -> Optional[Dict[str, Any]]:
        try:
            if not supabase:
                logger.error("âŒ Supabase no estÃ¡ inicializado")
                return None
                
            response = supabase.table("noticias").select("*").eq("id", noticia_id).execute()
            
            if not response.data:
                logger.warning(f"âŒ Noticia {noticia_id} no encontrada en Supabase")
                return None
            
            noticia = response.data[0]
            logger.info(f"âœ… Noticia {noticia_id} encontrada: {noticia['titulo'][:50]}...")
            
            return noticia
            
        except Exception as e:
            logger.error(f"âŒ Error obteniendo noticia {noticia_id}: {e}")
            return None
    
    def construir_contexto_noticia(self, noticia: Dict[str, Any]) -> str:
        contexto = f"""
ðŸ“° CONTEXTO DE NOTICIA PARA ANÃLISIS:

TITULAR: {noticia['titulo']}

RESUMEN COMPLETO: 
{noticia['resumen']}

INFORMACIÃ“N ADICIONAL:
â€¢ CategorÃ­a: {noticia.get('categoria', 'No especificada')}
â€¢ Fuente: {noticia.get('fuente', 'No especificada')}
â€¢ Fecha: {noticia.get('fecha', 'No especificada')}

INSTRUCCIONES PARA TI:
Eres un analista de noticias. El usuario te harÃ¡ preguntas SOBRE ESTA NOTICIA ESPECÃFICA.
â€¢ Responde basado ÃšNICAMENTE en la informaciÃ³n proporcionada arriba
â€¢ Si algo no estÃ¡ claro en la noticia, reconÃ³celo amablemente
â€¢ SÃ© objetivo y enfÃ³cate en los hechos presentados
â€¢ Puedes explicar el contexto y significado de lo que SÃ estÃ¡ en la noticia

EJEMPLO:
Si el usuario pregunta "Â¿QuÃ© pasÃ³ con [persona]?" â†’ Explica lo que la noticia dice sobre esa persona
Si pregunta "Â¿CuÃ¡ndo ocurriÃ³?" â†’ Usa las fechas de la noticia
Si pregunta "Â¿Por quÃ© es importante?" â†’ Analiza el impacto basado en el contenido
"""
        return contexto
    
    def llamar_gemini_api(self, prompt: str) -> str:
        try:
            if not gemini_model:
                logger.error("âŒ Gemini no estÃ¡ configurado correctamente")
                return self.get_fallback_response("")
            
            logger.info("ðŸ”„ Enviando pregunta a Gemini 2.5 Flash API...")
            
            generation_config = {
                "temperature": 0.3,
                "top_p": 0.9,
                "top_k": 40,
                "max_output_tokens": 800,
            }
            
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"}
            ]
            
            response = gemini_model.generate_content(
                prompt,
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            
            if response.text:
                respuesta = response.text.strip()
                logger.info("âœ… Respuesta recibida de Gemini 2.5 Flash")
                return respuesta
            else:
                logger.warning("âŒ Gemini no devolviÃ³ texto en la respuesta")
                return self.get_fallback_response(prompt)
                
        except Exception as e:
            logger.error(f"âŒ Error llamando a Gemini: {e}")
            return self.get_fallback_response(prompt)
    
    def get_fallback_response(self, prompt: str) -> str:
        if not gemini_model:
            return "ðŸ¤– Hola! Soy AntiBot de AntiHumo News. Actualmente estoy en modo de respuestas bÃ¡sicas. Puedo ayudarte a navegar el sitio y sus categorÃ­as. Â¿En quÃ© necesitas ayuda?"
        
        prompt_lower = prompt.lower()
        
        fallback_responses = {
            "hola": "Â¡Hola! ðŸ¤– Soy AntiBot de AntiHumo News. Puedo ayudarte a entender noticias especÃ­ficas o explicarte sobre nuestro sitio. Â¿En quÃ© necesitas ayuda?",
            "holaa": "Â¡Hola! ðŸ‘‹ Soy AntiBot. Puedo analizar noticias especÃ­ficas o ayudarte a navegar AntiHumo News. Â¿Sobre quÃ© noticia quieres hablar?",
            "quÃ© puedes hacer": "Puedo: ðŸ“° Analizar noticias especÃ­ficas publicadas, ðŸ” Explicar categorÃ­as del sitio, ðŸ“Š Ayudarte a navegar AntiHumo News. Â¿Sobre quÃ© noticia quieres hablar?",
            "noticias": "ðŸ“° En AntiHumo News encontrarÃ¡s noticias actualizadas de Argentina y el mundo, resumidas con IA para eliminar el amarillismo. Â¡Explora las diferentes categorÃ­as!",
            "clima": "ðŸŒ¤ï¸ En AntiHumo News tenemos una secciÃ³n de clima con pronÃ³sticos actualizados. Puedes consultarla en nuestro sitio para informaciÃ³n meteorolÃ³gica.",
            "deportes": "âš½ Tenemos una secciÃ³n dedicada a deportes con las Ãºltimas noticias. Â¡Navega por la categorÃ­a Deportes en AntiHumo News para ver lo Ãºltimo!",
            "tecnologÃ­a": "ðŸ’» En nuestra secciÃ³n de TecnologÃ­a encontrarÃ¡s las Ãºltimas novedades en innovaciÃ³n. Visita AntiHumo News para ver el contenido actualizado.",
            "ayuda": "ðŸ¤– Puedo ayudarte a entender noticias especÃ­ficas, explicar categorÃ­as del sitio y guiarte en AntiHumo News. Â¿Sobre quÃ© noticia necesitas informaciÃ³n?",
            "nasa": "ðŸš€ Tenemos contenido de la NASA incluyendo la Astronomy Picture of the Day (APOD). Â¡Es una de nuestras secciones mÃ¡s populares!",
            "mercados": "ðŸ“ˆ En AntiHumo News cubrimos noticias de mercados financieros y econÃ³micas. Revisa nuestra secciÃ³n de EconomÃ­a para estar actualizado.",
            "wall street": "ðŸ“Š Wall Street se basa en anÃ¡lisis de empresas, tendencias econÃ³micas, datos macroeconÃ³micos y expectativas de mercado para hacer sus estimaciones.",
            "economÃ­a": "ðŸ’¹ En nuestra secciÃ³n de EconomÃ­a encontrarÃ¡s anÃ¡lisis de mercados, tendencias financieras y noticias econÃ³micas actualizadas."
        }
        
        palabras_fuera_contexto = [
            "calcula", "resuelve", "ecuaciÃ³n", "matemÃ¡tica pura", 
            "consejo mÃ©dico", "consejo legal", "quÃ© droga", "ilegal",
            "futuro predicciÃ³n", "horÃ³scopo", "magia", "hechizo",
            "fÃ³rmula quÃ­mica", "teorema", "Ã¡lgebra", "trigonometrÃ­a"
        ]
        
        for palabra in palabras_fuera_contexto:
            if palabra in prompt_lower:
                return "ðŸš« Lo siento, no puedo ayudarte con ese tipo de consultas. Mi especialidad es noticias y contenido de AntiHumo News."
        
        for keyword, response in fallback_responses.items():
            if keyword in prompt_lower:
                return response
        
        if "wall street" in prompt_lower or "estimaciÃ³n" in prompt_lower or "mercado" in prompt_lower:
            return "ðŸ“ˆ Wall Street basa sus estimaciones en anÃ¡lisis fundamental de empresas, tendencias macroeconÃ³micas, datos histÃ³ricos, proyecciones de crecimiento y condiciones del mercado global."
        
        return "ðŸ¤– Â¡Hola! Soy AntiBot de AntiHumo News. Puedo ayudarte a entender noticias especÃ­ficas publicadas en nuestro sitio. Â¿Tienes alguna noticia en mente sobre la que quieras hablar? TambiÃ©n puedo explicarte las categorÃ­as y funcionalidades disponibles."
    
    def generar_respuesta(self, pregunta: str, noticia_id: Optional[int] = None, user_ip: str = "desconocida") -> Dict[str, Any]:
        try:
            rate_limit_check = self.verificar_rate_limit(user_ip)
            
            if not rate_limit_check["permitido"]:
                logger.warning(f"ðŸš« Rate limit excedido para IP: {user_ip}")
                return {
                    "respuesta": rate_limit_check["mensaje"],
                    "tipo_contexto": "rate_limit",
                    "noticia_id": noticia_id,
                    "noticia_info": "limite_excedido",
                    "titulo_noticia": None,
                    "exito": False,
                    "modelo": "rate_limit",
                    "rate_limit_info": rate_limit_check
                }
            
            if random.random() < 0.1:
                self.limpiar_cache_antiguo()
            
            if noticia_id:
                noticia_data = self.obtener_contexto_noticia(noticia_id)
                if noticia_data:
                    contexto = self.construir_contexto_noticia(noticia_data)
                    tipo_contexto = "noticia"
                    noticia_info = "noticia_encontrada"
                    titulo_noticia = noticia_data['titulo']
                else:
                    contexto = self.contexto_base
                    tipo_contexto = "general"
                    noticia_info = "noticia_no_encontrada"
                    titulo_noticia = None
            else:
                contexto = self.contexto_base
                tipo_contexto = "general"
                noticia_info = "sin_noticia"
                titulo_noticia = None
            
            prompt_final = f"""{contexto}

PREGUNTA DEL USUARIO: {pregunta}

RESPONDE AHORA (en espaÃ±ol, de forma natural y Ãºtil):"""
            
            respuesta = self.llamar_gemini_api(prompt_final)
            
            logger.info(f"âœ… Respuesta generada - Tipo: {tipo_contexto}, Longitud: {len(respuesta)}")
            
            return {
                "respuesta": respuesta,
                "tipo_contexto": tipo_contexto,
                "noticia_id": noticia_id,
                "noticia_info": noticia_info,
                "titulo_noticia": titulo_noticia,
                "exito": True,
                "modelo": self.modelo_actual,
                "rate_limit_info": rate_limit_check
            }
            
        except Exception as e:
            logger.error(f"âŒ Error generando respuesta: {e}")
            return {
                "respuesta": "âŒ Lo siento, ocurriÃ³ un error inesperado. Por favor, intenta nuevamente. âš ï¸",
                "tipo_contexto": "error",
                "noticia_id": noticia_id,
                "noticia_info": "error",
                "titulo_noticia": None,
                "exito": False,
                "modelo": "error",
                "rate_limit_info": None
            }


chatbot_service = ChatBotService()
print("âœ… ChatBot Service con Gemini 2.5 Flash (30 preguntas/dÃ­a) inicializado correctamente")

try:
    test_result = chatbot_service.generar_respuesta("Hola, Â¿estÃ¡s funcionando?", None, "test_init")
    if test_result["exito"]:
        print(f"âœ… Test inicial exitoso: {test_result['respuesta'][:50]}...")
    else:
        print(f"âš ï¸ Test inicial con problemas: {test_result['respuesta']}")
        print("ðŸ”§ El bot estÃ¡ en modo fallback. Verifica GEMINI_API_KEY_01 en Render.")
except Exception as e:
    print(f"âŒ Error en test inicial: {e}")