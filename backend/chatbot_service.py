import os
import requests
from supabase import create_client
from typing import Optional, Dict, Any
from dotenv import load_dotenv
from datetime import datetime, timedelta
import random
import google.generativeai as genai
import time

# Cargar variables de entorno
load_dotenv()

# ConfiguraciÃ³n de Supabase
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# ConfiguraciÃ³n de Gemini - NUEVA API KEY
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_01")  # âœ… NUEVA KEY
GEMINI_MODEL = "gemini-2.5-flash"  # âœ… MODELO ACTUALIZADO

# ConfiguraciÃ³n de Rate Limiting
MAX_REQUESTS_PER_DAY = 30  # âœ… LIMITADO A 30 PREGUNTAS POR DÃA

print("ðŸ”§ Inicializando ChatBot Service con Gemini...")
print(f"âœ… LÃ­mite: {MAX_REQUESTS_PER_DAY} preguntas por dÃ­a por IP")
print(f"âœ… GEMINI_API_KEY_01 cargada: {bool(GEMINI_API_KEY)}")
print(f"âœ… Supabase configurado: {bool(SUPABASE_URL)}")

# Configurar Gemini
try:
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)
        gemini_model = genai.GenerativeModel("gemini-2.5-flash")  # âœ… MODELO ACTUALIZADO
        print(f"âœ… Gemini configurado correctamente - Modelo: {GEMINI_MODEL}")
    else:
        print("âŒ GEMINI_API_KEY_01 no encontrada")
        gemini_model = None
except Exception as e:
    print(f"âŒ Error configurando Gemini: {e}")
    gemini_model = None

# Contexto base mejorado
CONTEXTO_BASE_WEB = """
Eres AntiBot, el asistente inteligente de AntiHumo News. Tu propÃ³sito es ayudar a los usuarios a encontrar informaciÃ³n veraz y objetiva.

SOBRE ANTIHUMO NEWS:
â€¢ Agregador de noticias argentinas y globales
â€¢ ResÃºmenes con IA que eliminan amarillismo
â€¢ InformaciÃ³n verificada y sin "humo" informativo
â€¢ Secciones: Noticias, Clima, Deportes, Mercados, NASA, TecnologÃ­a

INSTRUCCIONES:
â€¢ Responde SIEMPRE en espaÃ±ol
â€¢ SÃ© breve y directo (2-3 oraciones mÃ¡ximo)
â€¢ MantÃ©n tono profesional pero amigable
â€¢ Si no sabes algo, admÃ­telo amablemente
â€¢ Usa emojis moderadamente (ðŸš€ðŸ“°ðŸ”)
â€¢ Evita inventar informaciÃ³n

Responde de forma Ãºtil y veraz.
"""

class ChatBotService:
    def __init__(self):
        self.contexto_base = CONTEXTO_BASE_WEB
        self.modelo_actual = GEMINI_MODEL
        self.rate_limit_cache = {}
    
    def verificar_rate_limit(self, user_ip: str) -> Dict[str, Any]:
        """Verifica si el usuario ha excedido el lÃ­mite de 30 preguntas por dÃ­a."""
        ahora = datetime.now()
        fecha_actual = ahora.date()
        
        if user_ip in self.rate_limit_cache:
            cache_data = self.rate_limit_cache[user_ip]
            
            # Si es el mismo dÃ­a, verificar contador
            if cache_data['fecha'] == fecha_actual:
                if cache_data['contador'] >= MAX_REQUESTS_PER_DAY:
                    # Calcular tiempo hasta maÃ±ana
                    manana = ahora + timedelta(days=1)
                    manana_medianoche = manana.replace(hour=0, minute=0, second=0, microsecond=0)
                    segundos_restantes = (manana_medianoche - ahora).seconds
                    horas_restantes = segundos_restantes // 3600
                    minutos_restantes = (segundos_restantes % 3600) // 60
                    
                    return {
                        "permitido": False,
                        "mensaje": f"â° Has alcanzado el lÃ­mite de {MAX_REQUESTS_PER_DAY} preguntas por dÃ­a. PodrÃ¡s hacer mÃ¡s preguntas en {horas_restantes}h {minutos_restantes}m.",
                        "contador_actual": cache_data['contador'],
                        "limite": MAX_REQUESTS_PER_DAY,
                        "reset_time": manana_medianoche.isoformat()
                    }
                else:
                    # Incrementar contador
                    cache_data['contador'] += 1
                    preguntas_restantes = MAX_REQUESTS_PER_DAY - cache_data['contador']
                    return {
                        "permitido": True,
                        "mensaje": f"ðŸ“Š Usadas: {cache_data['contador']}/{MAX_REQUESTS_PER_DAY} | Restantes: {preguntas_restantes}",
                        "contador_actual": cache_data['contador'],
                        "limite": MAX_REQUESTS_PER_DAY,
                        "preguntas_restantes": preguntas_restantes
                    }
            else:
                # Nuevo dÃ­a, resetear contador
                self.rate_limit_cache[user_ip] = {
                    'fecha': fecha_actual,
                    'contador': 1
                }
                return {
                    "permitido": True,
                    "mensaje": f"ðŸ“Š Usadas: 1/{MAX_REQUESTS_PER_DAY} | Restantes: {MAX_REQUESTS_PER_DAY - 1}",
                    "contador_actual": 1,
                    "limite": MAX_REQUESTS_PER_DAY,
                    "preguntas_restantes": MAX_REQUESTS_PER_DAY - 1
                }
        else:
            # Primera pregunta de esta IP
            self.rate_limit_cache[user_ip] = {
                'fecha': fecha_actual,
                'contador': 1
            }
            return {
                "permitido": True,
                "mensaje": f"ðŸ“Š Usadas: 1/{MAX_REQUESTS_PER_DAY} | Restantes: {MAX_REQUESTS_PER_DAY - 1}",
                "contador_actual": 1,
                "limite": MAX_REQUESTS_PER_DAY,
                "preguntas_restantes": MAX_REQUESTS_PER_DAY - 1
            }
    
    def limpiar_cache_antiguo(self):
        """Limpia entradas de cache mÃ¡s antiguas de 2 dÃ­as."""
        fecha_actual = datetime.now().date()
        ips_a_eliminar = []
        
        for ip, data in self.rate_limit_cache.items():
            if (fecha_actual - data['fecha']).days > 2:
                ips_a_eliminar.append(ip)
        
        for ip in ips_a_eliminar:
            del self.rate_limit_cache[ip]
            
        if ips_a_eliminar:
            print(f"ðŸ§¹ Limpiadas {len(ips_a_eliminar)} IPs antiguas del cache")
    
    def obtener_contexto_noticia(self, noticia_id: int) -> Optional[Dict[str, Any]]:
        """Obtiene TODOS los datos de una noticia desde Supabase."""
        try:
            response = supabase.table("noticias").select("*").eq("id", noticia_id).execute()
            
            if not response.data:
                print(f"âŒ Noticia {noticia_id} no encontrada en Supabase")
                return None
            
            noticia = response.data[0]
            print(f"âœ… Noticia {noticia_id} encontrada: {noticia['titulo'][:50]}...")
            
            return noticia
            
        except Exception as e:
            print(f"âŒ Error obteniendo noticia {noticia_id}: {e}")
            return None
    
    def construir_contexto_noticia(self, noticia: Dict[str, Any]) -> str:
        """Construye un contexto rico con todos los datos de la noticia."""
        
        contexto = f"""
ðŸ“° CONTEXTO COMPLETO DE LA NOTICIA:

**TITULAR:** {noticia['titulo']}

**RESUMEN COMPLETO:** 
{noticia['resumen']}

**INFORMACIÃ“N ADICIONAL:**
â€¢ ðŸ·ï¸ CategorÃ­a: {noticia.get('categoria', 'No especificada')}
â€¢ ðŸ“¢ Fuente: {noticia.get('fuente', 'No especificada')}
â€¢ ðŸ“… Fecha: {noticia.get('fecha', 'No especificada')}
â€¢ ðŸ”— Enlace original: {noticia.get('url', 'No disponible')}
â€¢ ðŸ‘ï¸ Vistas: {noticia.get('clics', 0)} clics

**INSTRUCCIONES ESPECÃFICAS:**
1. Responde ÃšNICAMENTE basado en la informaciÃ³n de esta noticia
2. Si la pregunta no puede responderse con esta noticia, di: "No tengo esa informaciÃ³n especÃ­fica en esta noticia. Te sugiero leer la noticia completa en el enlace proporcionado."
3. SÃ© objetivo y enfÃ³cate en los hechos del resumen
4. Destaca los puntos clave de lo que sÃ­ estÃ¡ en la noticia
5. MÃ¡ximo 3 oraciones por respuesta

**IMPORTANTE:** Tu valor estÃ¡ en resumir y aclarar lo que SÃ estÃ¡ en la noticia, no en adivinar lo que no estÃ¡.
"""
        return contexto
    
    def llamar_gemini_api(self, prompt: str) -> str:
        """Llama a la API de Gemini para obtener respuestas de IA."""
        try:
            if not GEMINI_API_KEY or not gemini_model:
                print("âŒ Gemini no configurado correctamente")
                return self.get_fallback_response(prompt)
            
            print("ðŸ”„ Enviando pregunta a Gemini API...")
            
            # Configurar la generaciÃ³n
            generation_config = {
                "temperature": 0.3,
                "top_p": 0.9,
                "top_k": 40,
                "max_output_tokens": 350,
            }
            
            # Enviar prompt a Gemini
            response = gemini_model.generate_content(
                prompt,
                generation_config=generation_config
            )
            
            if response.text:
                respuesta = response.text.strip()
                print("âœ… Respuesta recibida de Gemini")
                return respuesta
            else:
                print("âŒ Gemini no devolviÃ³ texto")
                return self.get_fallback_response(prompt)
                
        except Exception as e:
            print(f"âŒ Error llamando a Gemini: {e}")
            return self.get_fallback_response(prompt)
    
    def get_fallback_response(self, prompt: str) -> str:
        """Respuestas de fallback cuando Gemini no funciona."""
        fallback_responses = {
            "hola": "Â¡Hola! ðŸ¤– Soy AntiBot de AntiHumo News. Estoy aquÃ­ para ayudarte con informaciÃ³n sobre noticias y el sitio. Â¿En quÃ© puedo asistirte?",
            "holaa": "Â¡Hola! ðŸ‘‹ Soy AntiBot, tu asistente de AntiHumo News. Puedo ayudarte a encontrar noticias e informaciÃ³n veraz. Â¿QuÃ© te gustarÃ­a saber?",
            "quÃ© puedes hacer": "Puedo: ðŸ“° Responder sobre noticias especÃ­ficas, ðŸ” Ayudarte a navegar el sitio, ðŸ“Š Dar informaciÃ³n general sobre AntiHumo News. Â¿En quÃ© te puedo ayudar?",
            "noticias": "ðŸ“° En AntiHumo News encontrarÃ¡s noticias actualizadas de Argentina y el mundo, resumidas con IA para eliminar el amarillismo. Â¡Explora las diferentes categorÃ­as!",
            "clima": "ðŸŒ¤ï¸ Para informaciÃ³n del clima en tiempo real, te sugiero consultar servicios especializados como el Servicio MeteorolÃ³gico Nacional. En AntiHumo nos enfocamos en noticias veraces.",
            "deportes": "âš½ Tenemos una secciÃ³n dedicada a deportes con las Ãºltimas noticias de fÃºtbol, tenis, y mÃ¡s. Â¡Navega por la categorÃ­a Deportes para ver lo Ãºltimo!",
            "tecnologÃ­a": "ðŸ’» En nuestra secciÃ³n de TecnologÃ­a encontrarÃ¡s las Ãºltimas novedades en IA, gadgets, startups y innovaciÃ³n. Â¡Ã‰chale un vistazo!",
            "ayuda": "ðŸ¤– Puedo ayudarte con: informaciÃ³n sobre noticias especÃ­ficas, navegaciÃ³n del sitio, categorÃ­as disponibles, y temas generales de AntiHumo News. Â¿QuÃ© necesitas?"
        }
        
        # Buscar palabras clave en el prompt
        prompt_lower = prompt.lower()
        
        for keyword, response in fallback_responses.items():
            if keyword in prompt_lower:
                return response
        
        # Respuesta por defecto
        default_responses = [
            "ðŸ¤– Â¡Hola! Soy AntiBot. Puedo ayudarte con informaciÃ³n sobre noticias y navegaciÃ³n del sitio. Â¿En quÃ© puedo asistirte especÃ­ficamente?",
            "ðŸ“° Hola, soy AntiBot. Estoy aquÃ­ para ayudarte a encontrar informaciÃ³n veraz en AntiHumo News. Â¿QuÃ© te gustarÃ­a saber?",
            "ðŸ” Â¡Hola! Como AntiBot, puedo ayudarte con noticias y contenido del sitio. Â¿En quÃ© tema necesitas ayuda?"
        ]
        
        return random.choice(default_responses)
    
    def generar_respuesta(self, pregunta: str, noticia_id: Optional[int] = None, user_ip: str = "desconocida") -> Dict[str, Any]:
        """Genera una respuesta contextual basada en la noticia o contexto general."""
        try:
            # âœ… PRIMERO verificar rate limiting
            rate_limit_check = self.verificar_rate_limit(user_ip)
            
            if not rate_limit_check["permitido"]:
                return {
                    "respuesta": rate_limit_check["mensaje"],
                    "tipo_contexto": "rate_limit",
                    "noticia_id": noticia_id,
                    "noticia_info": "limite_excedido",
                    "titulo_noticia": None,
                    "exito": False,
                    "modelo": "rate_limit",
                    "rate_limit_info": rate_limit_check
                }
            
            # Limpiar cache antiguo periÃ³dicamente (10% de probabilidad)
            if random.random() < 0.1:
                self.limpiar_cache_antiguo()
            
            # Determinar el contexto a usar
            if noticia_id:
                noticia_data = self.obtener_contexto_noticia(noticia_id)
                if noticia_data:
                    contexto = self.construir_contexto_noticia(noticia_data)
                    tipo_contexto = "noticia"
                    noticia_info = "noticia_encontrada"
                    titulo_noticia = noticia_data['titulo']
                else:
                    contexto = self.contexto_base
                    tipo_contexto = "general"
                    noticia_info = "noticia_no_encontrada"
                    titulo_noticia = None
            else:
                contexto = self.contexto_base
                tipo_contexto = "general"
                noticia_info = "sin_noticia"
                titulo_noticia = None
            
            # Construir prompt final optimizado
            prompt_final = f"""{contexto}

**PREGUNTA DEL USUARIO:** {pregunta}

**RESPONDE AHORA** (en espaÃ±ol, breve y directo):"""
            
            # Obtener respuesta del modelo
            respuesta = self.llamar_gemini_api(prompt_final)
            
            return {
                "respuesta": respuesta,
                "tipo_contexto": tipo_contexto,
                "noticia_id": noticia_id,
                "noticia_info": noticia_info,
                "titulo_noticia": titulo_noticia,
                "exito": True,
                "modelo": self.modelo_actual,
                "rate_limit_info": rate_limit_check
            }
            
        except Exception as e:
            print(f"âŒ Error generando respuesta: {e}")
            return {
                "respuesta": "âŒ Lo siento, ocurriÃ³ un error inesperado. Por favor, intenta nuevamente. âš ï¸",
                "tipo_contexto": "error",
                "noticia_id": noticia_id,
                "noticia_info": "error",
                "titulo_noticia": None,
                "exito": False,
                "modelo": "error",
                "rate_limit_info": None
            }

# Instancia global del servicio
chatbot_service = ChatBotService()
print("âœ… ChatBot Service con Gemini 2.5 Flash (30 preguntas/dÃ­a) inicializado correctamente")