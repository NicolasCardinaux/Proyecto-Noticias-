# db.py - Conexi√≥n completa a Supabase con todas las optimizaciones
import os
from supabase import create_client, Client
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import hashlib
import random

load_dotenv()

# Configuraci√≥n de Supabase
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    raise ValueError("‚ùå Faltan SUPABASE_URL o SUPABASE_SERVICE_ROLE_KEY en .env")

# Cliente de Supabase
try:
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("‚úÖ Cliente Supabase 2.3.1 configurado correctamente")
except Exception as e:
    print(f"‚ùå Error creando cliente Supabase: {e}")
    raise

def _handle_response(response):
    """Maneja respuestas de Supabase."""
    if hasattr(response, 'error') and response.error:
        raise Exception(f"Supabase error: {response.error}")
    return response.data if hasattr(response, 'data') else response

# ==================== FUNCIONES PARA NOTICIAS ====================

def get_noticias(limit: Optional[int] = None) -> List[Dict[str, Any]]:
    """Obtiene todas las noticias ordenadas por fecha descendente."""
    try:
        query = supabase.table("noticias").select("*").order("fecha", desc=True)
        if limit:
            query = query.limit(limit)
        response = query.execute()
        return _handle_response(response)
    except Exception as e:
        print(f"‚ùå Error obteniendo noticias: {e}")
        return []

def get_popular_posts(limit: int = 5, exclude_id: Optional[int] = None) -> List[Dict[str, Any]]:
    """Obtiene posts populares ordenados por clics."""
    try:
        query = supabase.table("noticias").select("*").order("clics", desc=True).limit(limit)
        if exclude_id:
            query = query.neq("id", exclude_id)
        response = query.execute()
        return _handle_response(response)
    except Exception as e:
        print(f"‚ùå Error obteniendo posts populares: {e}")
        return []

def get_random_posts(limit: int = 4) -> List[Dict[str, Any]]:
    """Obtiene noticias aleatorias - VERSI√ìN OPTIMIZADA."""
    try:
        # Intentar usar RANDOM() de PostgreSQL si est√° disponible
        try:
            response = supabase.table("noticias").select("*").order("random()").limit(limit).execute()
            return _handle_response(response)
        except:
            # Fallback: obtener sample y mezclar en Python
            sample_size = min(limit * 3, 50)
            response = supabase.table("noticias").select("*").order("fecha", desc=True).limit(sample_size).execute()
            noticias = _handle_response(response)
            
            if not noticias:
                return []
                
            random.shuffle(noticias)
            return noticias[:limit]
            
    except Exception as e:
        print(f"‚ùå Error obteniendo posts aleatorios: {e}")
        return []

def get_latest_by_category() -> List[Dict[str, Any]]:
    """Obtiene la √∫ltima noticia de cada categor√≠a."""
    try:
        noticias = get_noticias()
        latest = {}
        for noticia in noticias:
            categoria = noticia.get("categoria") or "Sin categor√≠a"
            if categoria not in latest and len(latest) < 6:
                latest[categoria] = noticia
        return list(latest.values())
    except Exception as e:
        print(f"‚ùå Error obteniendo √∫ltimas por categor√≠a: {e}")
        return []

def get_related_posts(categoria: str, exclude_id: Optional[int] = None, limit: int = 3) -> List[Dict[str, Any]]:
    """Obtiene noticias relacionadas por categor√≠a."""
    try:
        query = supabase.table("noticias").select("*").eq("categoria", categoria).order("fecha", desc=True).limit(limit)
        if exclude_id:
            query = query.neq("id", exclude_id)
        response = query.execute()
        return _handle_response(response)
    except Exception as e:
        print(f"‚ùå Error obteniendo posts relacionados: {e}")
        return []

def get_posts_by_source(fuente: str, limit: int = 10) -> List[Dict[str, Any]]:
    """Obtiene noticias por fuente."""
    try:
        response = supabase.table("noticias").select("*").eq("fuente", fuente).order("fecha", desc=True).limit(limit).execute()
        return _handle_response(response)
    except Exception as e:
        print(f"‚ùå Error obteniendo posts por fuente: {e}")
        return []

def get_categories() -> List[str]:
    """Obtiene todas las categor√≠as disponibles."""
    try:
        response = supabase.table("noticias").select("categoria").execute()
        categorias = _handle_response(response)
        return list(set([cat["categoria"] for cat in categorias if cat["categoria"]]))
    except Exception as e:
        print(f"‚ùå Error obteniendo categor√≠as: {e}")
        return []

def get_sources() -> List[str]:
    """Obtiene todas las fuentes disponibles."""
    try:
        response = supabase.table("noticias").select("fuente").execute()
        fuentes = _handle_response(response)
        return list(set([src["fuente"] for src in fuentes if src["fuente"]]))
    except Exception as e:
        print(f"‚ùå Error obteniendo fuentes: {e}")
        return []

def get_stats() -> Dict[str, Any]:
    """Obtiene estad√≠sticas generales."""
    try:
        # Total de noticias
        total_response = supabase.table("noticias").select("id", count="exact").execute()
        total_noticias = len(total_response.data)
        
        # Total de clics
        clics_response = supabase.table("noticias").select("clics").execute()
        total_clics = sum(noticia.get("clics", 0) for noticia in clics_response.data)
        
        # Noticias de hoy (usando fecha ISO para compatibilidad)
        hoy = datetime.now().date().isoformat()
        hoy_response = supabase.table("noticias").select("id").eq("fecha", hoy).execute()
        noticias_hoy = len(hoy_response.data)
        
        return {
            "total_noticias": total_noticias,
            "total_clics": total_clics,
            "noticias_hoy": noticias_hoy
        }
    except Exception as e:
        print(f"‚ùå Error obteniendo estad√≠sticas: {e}")
        return {"total_noticias": 0, "total_clics": 0, "noticias_hoy": 0}

def search_noticias(query: str, tipo: str = "titulo") -> List[Dict[str, Any]]:
    """Busca noticias por t√©rmino."""
    try:
        if tipo == "fuente":
            response = supabase.table("noticias").select("*").ilike("fuente", f"%{query}%").order("fecha", desc=True).execute()
        elif tipo == "categoria":
            response = supabase.table("noticias").select("*").ilike("categoria", f"%{query}%").order("fecha", desc=True).execute()
        else:
            response = supabase.table("noticias").select("*").ilike("titulo", f"%{query}%").order("fecha", desc=True).execute()
        return _handle_response(response)
    except Exception as e:
        print(f"‚ùå Error buscando noticias: {e}")
        return []

# ==================== OPERACIONES DE ESCRITURA ====================

def insert_noticia(noticia: Dict[str, Any]) -> Dict[str, Any]:
    """Inserta una nueva noticia con manejo elegante de duplicados."""
    try:
        response = supabase.table("noticias").insert(noticia).execute()
        return _handle_response(response)
    except Exception as e:
        error_msg = str(e)
        if "duplicate key" in error_msg or "23505" in error_msg:
            raise Exception("Noticia duplicada") from e
        else:
            raise e

def noticia_existe(titulo: str, url: str) -> bool:
    """Verifica si una noticia ya existe por t√≠tulo o URL."""
    try:
        titulo_hash = generar_hash_titulo(titulo)
        response = supabase.table("noticias").select("id").or_(f"url.eq.{url},titulo_hash.eq.{titulo_hash}").execute()
        return len(response.data) > 0
    except Exception as e:
        print(f"‚ùå Error verificando existencia: {e}")
        return False

def obtener_urls_existentes() -> set:
    """Obtiene todas las URLs existentes en la base de datos."""
    try:
        response = supabase.table("noticias").select("url").execute()
        return {item["url"] for item in response.data}
    except Exception as e:
        print(f"‚ùå Error obteniendo URLs existentes: {e}")
        return set()

def increment_clics(noticia_id: int) -> bool:
    """Incrementa el contador de clics de una noticia - VERSI√ìN AT√ìMICA."""
    try:
        # Intentar usar funci√≥n RPC si existe (m√°s eficiente y at√≥mica)
        try:
            response = supabase.rpc("increment_clics", {"nid": noticia_id}).execute()
            _handle_response(response)
            return True
        except:
            # Fallback: actualizaci√≥n directa
            response = supabase.table("noticias").select("clics").eq("id", noticia_id).execute()
            if not response.data:
                return False
                
            current_clics = response.data[0].get("clics", 0)
            new_clics = current_clics + 1
            
            update_response = supabase.table("noticias").update({"clics": new_clics}).eq("id", noticia_id).execute()
            return True
            
    except Exception as e:
        print(f"‚ùå Error incrementando clics: {e}")
        return False

def delete_old_noticias(max_months: int = 6) -> bool:
    """Elimina noticias m√°s antiguas que X meses."""
    try:
        # Usar fecha ISO para m√°xima compatibilidad
        fecha_limite = (datetime.now() - timedelta(days=30 * max_months)).date().isoformat()
        
        print(f"üóëÔ∏è  Buscando noticias anteriores a: {fecha_limite} ({max_months} meses)")
        
        # Contar noticias a eliminar
        count_response = supabase.table("noticias").select("id", count="exact").lt("fecha", fecha_limite).execute()
        total_a_eliminar = count_response.count or 0
        
        if total_a_eliminar == 0:
            print("‚úÖ No hay noticias antiguas para eliminar")
            return True
        
        stats_antes = get_stats()
        
        # Eliminar
        delete_response = supabase.table("noticias").delete().lt("fecha", fecha_limite).execute()
        
        deleted_count = len(delete_response.data) if delete_response.data else 0
        stats_despues = get_stats()
        
        print(f"‚úÖ Eliminadas {deleted_count} noticias con m√°s de {max_months} meses")
        print(f"üìä Estad√≠sticas: {stats_antes['total_noticias']} ‚Üí {stats_despues['total_noticias']} noticias")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error eliminando noticias antiguas: {e}")
        return False

# ==================== FUNCIONES PARA CACH√â APOD ====================

def get_cached_apod_translation(apod_date: str, user_ip: str) -> Optional[Dict[str, Any]]:
    """Obtiene la traducci√≥n del APOD del cach√©."""
    try:
        response = supabase.table("apod_translation_cache").select("*").eq("apod_date", apod_date).eq("user_ip", user_ip).execute()
        return response.data[0] if response.data else None
    except Exception as e:
        print(f"‚ùå Error obteniendo cach√© APOD: {e}")
        return None

def save_apod_translation(apod_date: str, content_hash: str, translated_title: str, translated_explanation: str, user_ip: str) -> bool:
    """Guarda la traducci√≥n del APOD en el cach√©."""
    try:
        data = {
            "apod_date": apod_date,
            "content_hash": content_hash,
            "translated_title": translated_title,
            "translated_explanation": translated_explanation,
            "user_ip": user_ip
        }
        response = supabase.table("apod_translation_cache").insert(data).execute()
        return True
    except Exception as e:
        print(f"‚ùå Error guardando cach√© APOD: {e}")
        return False

# ==================== UTILIDADES ====================

def generar_hash_titulo(titulo: str) -> str:
    """Genera un hash √∫nico del t√≠tulo para detectar duplicados."""
    return hashlib.md5(titulo.strip().lower().encode('utf-8')).hexdigest()

def inicializar_db():
    """Funci√≥n de inicializaci√≥n completa."""
    print("‚úÖ Base de datos Supabase configurada correctamente.")
    stats = get_stats()
    print(f"üìä Estado inicial: {stats['total_noticias']} noticias, {stats['total_clics']} clics totales")

# ==================== FUNCIONES DE AN√ÅLISIS Y MONITOREO ====================

def analizar_antiguedad_noticias():
    """Analiza la distribuci√≥n de noticias por antig√ºedad."""
    try:
        from collections import Counter
        
        noticias = get_noticias()
        if not noticias:
            print("üìä No hay noticias para analizar")
            return
        
        hoy = datetime.now().date()
        categorias_antiguedad = []
        
        for noticia in noticias:
            try:
                # Usar fecha ISO para compatibilidad
                fecha_noticia = datetime.strptime(noticia['fecha'], "%Y-%m-%d").date()
                dias_diferencia = (hoy - fecha_noticia).days
                meses_diferencia = dias_diferencia // 30
                
                if meses_diferencia < 1:
                    categoria = "Menos de 1 mes"
                elif meses_diferencia < 3:
                    categoria = "1-3 meses" 
                elif meses_diferencia < 6:
                    categoria = "3-6 meses"
                elif meses_diferencia < 12:
                    categoria = "6-12 meses"
                else:
                    categoria = "M√°s de 1 a√±o"
                    
                categorias_antiguedad.append(categoria)
                
            except Exception as e:
                categorias_antiguedad.append("Fecha inv√°lida")
        
        # Contar por categor√≠a
        conteo = Counter(categorias_antiguedad)
        
        print("üìä DISTRIBUCI√ìN POR ANTIG√úEDAD:")
        print("-" * 40)
        for categoria, cantidad in conteo.most_common():
            porcentaje = (cantidad / len(noticias)) * 100
            print(f"   {categoria}: {cantidad} noticias ({porcentaje:.1f}%)")
            
        total = len(noticias)
        mas_de_6_meses = sum(1 for cat in categorias_antiguedad if cat in ["6-12 meses", "M√°s de 1 a√±o"])
        
        if mas_de_6_meses > 0:
            print(f"\n‚ö†Ô∏è  {mas_de_6_meses} noticias ({mas_de_6_meses/total*100:.1f}%) tienen m√°s de 6 meses")
            print("   Se eliminar√°n en la pr√≥xima limpieza autom√°tica")
        else:
            print(f"\n‚úÖ Todas las noticias tienen menos de 6 meses")
            
        return conteo
            
    except Exception as e:
        print(f"‚ùå Error analizando antig√ºedad: {e}")
        return None

def get_noticias_proximas_a_expirar(dias_umbral: int = 30):
    """Obtiene noticias que est√°n pr√≥ximas a cumplir 6 meses."""
    try:
        fecha_umbral = (datetime.now() - timedelta(days=180 - dias_umbral)).date().isoformat()
        fecha_limite = (datetime.now() - timedelta(days=180)).date().isoformat()
        
        response = supabase.table("noticias").select("*").lt("fecha", fecha_umbral).gt("fecha", fecha_limite).order("fecha", desc=True).execute()
        
        noticias_proximas = _handle_response(response)
        
        if noticias_proximas:
            print(f"\n‚ö†Ô∏è  NOTICIAS PR√ìXIMAS A EXPIRAR (en los pr√≥ximos {dias_umbral} d√≠as):")
            print("-" * 50)
            for noticia in noticias_proximas:
                dias_restantes = 180 - (datetime.now().date() - datetime.strptime(noticia['fecha'], "%Y-%m-%d").date()).days
                print(f"   üì∞ {noticia['titulo'][:60]}...")
                print(f"      Fecha: {noticia['fecha']} - Expira en: {dias_restantes} d√≠as")
                print()
        else:
            print(f"‚úÖ No hay noticias pr√≥ximas a expirar en los pr√≥ximos {dias_umbral} d√≠as")
            
        return noticias_proximas
        
    except Exception as e:
        print(f"‚ùå Error obteniendo noticias pr√≥ximas a expirar: {e}")
        return []

def monitor_estado_base_datos():
    """Monitoreo completo del estado de la base de datos."""
    print("üîç MONITOREO COMPLETO DE LA BASE DE DATOS")
    print("=" * 60)
    
    # Estad√≠sticas generales
    stats = get_stats()
    print(f"üìà ESTAD√çSTICAS GENERALES:")
    print(f"   ‚Ä¢ Total noticias: {stats['total_noticias']}")
    print(f"   ‚Ä¢ Total clics: {stats['total_clics']}")
    print(f"   ‚Ä¢ Noticias hoy: {stats['noticias_hoy']}")
    
    print("\nüìä DISTRIBUCI√ìN POR ANTIG√úEDAD:")
    analizar_antiguedad_noticias()
    
    print("\nüîî NOTICIAS PR√ìXIMAS A EXPIRAR:")
    get_noticias_proximas_a_expirar(dias_umbral=30)
    
    # √öltimas noticias agregadas
    ultimas = get_noticias(limit=3)
    if ultimas:
        print("\nüÜï √öLTIMAS NOTICIAS AGREGADAS:")
        for i, noticia in enumerate(ultimas, 1):
            print(f"   {i}. {noticia['titulo'][:70]}...")
            print(f"      üìÖ {noticia['fecha']} | üìä {noticia.get('clics', 0)} clics")
    
    print("\n" + "=" * 60)
    print("‚úÖ MONITOREO COMPLETADO")

if __name__ == "__main__":
    monitor_estado_base_datos()